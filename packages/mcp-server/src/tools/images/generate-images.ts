// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.

import { isJqError, maybeFilter } from 'dedalus-labs-mcp/filtering';
import { Metadata, asErrorResult, asTextContentResult } from 'dedalus-labs-mcp/tools/types';

import { Tool } from '@modelcontextprotocol/sdk/types.js';
import Dedalus from 'dedalus-labs';

export const metadata: Metadata = {
  resource: 'images',
  operation: 'write',
  tags: [],
  httpMethod: 'post',
  httpPath: '/v1/images/generations',
  operationId: 'create_image_v1_images_generations_post',
};

export const tool: Tool = {
  name: 'generate_images',
  description:
    "When using this tool, always use the `jq_filter` parameter to reduce the response size and improve performance.\n\nOnly omit if you're sure you don't need the data.\n\nGenerate images from text prompts.\n\nPure image generation models only (DALL-E, GPT Image).\nFor multimodal models like gemini-2.5-flash-image, use /v1/chat/completions.\n\n# Response Schema\n```json\n{\n  $ref: '#/$defs/images_response',\n  $defs: {\n    images_response: {\n      type: 'object',\n      title: 'ImagesResponse',\n      description: 'Response from image generation.',\n      properties: {\n        created: {\n          type: 'integer',\n          title: 'Created',\n          description: 'Unix timestamp when images were created'\n        },\n        data: {\n          type: 'array',\n          title: 'Data',\n          description: 'List of generated images',\n          items: {\n            $ref: '#/$defs/image'\n          }\n        }\n      },\n      required: [        'created',\n        'data'\n      ]\n    },\n    image: {\n      type: 'object',\n      title: 'Image',\n      description: 'Single image object.',\n      properties: {\n        b64_json: {\n          type: 'string',\n          title: 'B64 Json',\n          description: 'Base64-encoded image data (if response_format=b64_json)'\n        },\n        revised_prompt: {\n          type: 'string',\n          title: 'Revised Prompt',\n          description: 'Revised prompt used for generation (dall-e-3)'\n        },\n        url: {\n          type: 'string',\n          title: 'Url',\n          description: 'URL of the generated image (if response_format=url)'\n        }\n      }\n    }\n  }\n}\n```",
  inputSchema: {
    type: 'object',
    properties: {
      prompt: {
        type: 'string',
        title: 'Prompt',
        description:
          'A text description of the desired image(s). The maximum length is 32000 characters for `gpt-image-1`, 1000 characters for `dall-e-2` and 4000 characters for `dall-e-3`.',
      },
      background: {
        type: 'string',
        title: 'Background',
        description:
          'Allows to set transparency for the background of the generated image(s).\nThis parameter is only supported for `gpt-image-1`. Must be one of\n`transparent`, `opaque` or `auto` (default value). When `auto` is used, the\nmodel will automatically determine the best background for the image.\n\nIf `transparent`, the output format needs to support transparency, so it\nshould be set to either `png` (default value) or `webp`.',
        enum: ['transparent', 'opaque', 'auto'],
      },
      model: {
        type: 'string',
        title: 'Model',
        description:
          'The model to use for image generation. One of `openai/dall-e-2`, `openai/dall-e-3`, or `openai/gpt-image-1`. Defaults to `openai/dall-e-2` unless a parameter specific to `gpt-image-1` is used.',
      },
      moderation: {
        type: 'string',
        title: 'Moderation',
        description:
          'Control the content-moderation level for images generated by `gpt-image-1`. Must be either `low` for less restrictive filtering or `auto` (default value).',
        enum: ['low', 'auto'],
      },
      n: {
        type: 'integer',
        title: 'N',
        description:
          'The number of images to generate. Must be between 1 and 10. For `dall-e-3`, only `n=1` is supported.',
      },
      output_compression: {
        type: 'integer',
        title: 'Output Compression',
        description:
          'The compression level (0-100%) for the generated images. This parameter is only supported for `gpt-image-1` with the `webp` or `jpeg` output formats, and defaults to 100.',
      },
      output_format: {
        type: 'string',
        title: 'Output Format',
        description:
          'The format in which the generated images are returned. This parameter is only supported for `gpt-image-1`. Must be one of `png`, `jpeg`, or `webp`.',
        enum: ['png', 'jpeg', 'webp'],
      },
      partial_images: {
        type: 'integer',
        title: 'Partial Images',
        description:
          'The number of partial images to generate. This parameter is used for\nstreaming responses that return partial images. Value must be between 0 and 3.\nWhen set to 0, the response will be a single image sent in one streaming event.\n\nNote that the final image may be sent before the full number of partial images\nare generated if the full image is generated more quickly.',
      },
      quality: {
        type: 'string',
        title: 'Quality',
        description:
          'The quality of the image that will be generated.\n\n- `auto` (default value) will automatically select the best quality for the given model.\n- `high`, `medium` and `low` are supported for `gpt-image-1`.\n- `hd` and `standard` are supported for `dall-e-3`.\n- `standard` is the only option for `dall-e-2`.',
        enum: ['auto', 'high', 'medium', 'low', 'hd', 'standard'],
      },
      response_format: {
        type: 'string',
        title: 'Response Format',
        description:
          "The format in which generated images with `dall-e-2` and `dall-e-3` are returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes after the image has been generated. This parameter isn't supported for `gpt-image-1` which will always return base64-encoded images.",
        enum: ['url', 'b64_json'],
      },
      size: {
        type: 'string',
        title: 'Size',
        description:
          'The size of the generated images. Must be one of `1024x1024`, `1536x1024` (landscape), `1024x1536` (portrait), or `auto` (default value) for `gpt-image-1`, one of `256x256`, `512x512`, or `1024x1024` for `dall-e-2`, and one of `1024x1024`, `1792x1024`, or `1024x1792` for `dall-e-3`.',
        enum: ['256x256', '512x512', '1024x1024', '1536x1024', '1024x1536', '1792x1024', '1024x1792', 'auto'],
      },
      stream: {
        type: 'boolean',
        title: 'Stream',
        description:
          'Generate the image in streaming mode. Defaults to `false`. See the\n[Image generation guide](https://platform.openai.com/docs/guides/image-generation) for more information.\nThis parameter is only supported for `gpt-image-1`.',
      },
      style: {
        type: 'string',
        title: 'Style',
        description:
          'The style of the generated images. This parameter is only supported for `dall-e-3`. Must be one of `vivid` or `natural`. Vivid causes the model to lean towards generating hyper-real and dramatic images. Natural causes the model to produce more natural, less hyper-real looking images.',
        enum: ['vivid', 'natural'],
      },
      user: {
        type: 'string',
        title: 'User',
        description:
          'A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#end-user-ids).',
      },
      jq_filter: {
        type: 'string',
        title: 'jq Filter',
        description:
          'A jq filter to apply to the response to include certain fields. Consult the output schema in the tool description to see the fields that are available.\n\nFor example: to include only the `name` field in every object of a results array, you can provide ".results[].name".\n\nFor more information, see the [jq documentation](https://jqlang.org/manual/).',
      },
    },
    required: ['prompt'],
  },
  annotations: {},
};

export const handler = async (client: Dedalus, args: Record<string, unknown> | undefined) => {
  const { jq_filter, ...body } = args as any;
  try {
    return asTextContentResult(await maybeFilter(jq_filter, await client.images.generate(body)));
  } catch (error) {
    if (isJqError(error)) {
      return asErrorResult(error.message);
    }
    throw error;
  }
};

export default { metadata, tool, handler };
