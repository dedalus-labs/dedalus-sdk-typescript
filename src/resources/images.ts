// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.

import { APIResource } from '../core/resource';
import { APIPromise } from '../core/api-promise';
import { type Uploadable } from '../core/uploads';
import { RequestOptions } from '../internal/request-options';
import { multipartFormRequestOptions } from '../internal/uploads';

export class Images extends APIResource {
  /**
   * Create variations of an image.
   *
   * DALLÂ·E 2 only. Upload an image to generate variations.
   */
  createVariation(body: ImageCreateVariationParams, options?: RequestOptions): APIPromise<ImagesResponse> {
    return this._client.post(
      '/v1/images/variations',
      multipartFormRequestOptions({ body, ...options }, this._client),
    );
  }

  /**
   * Edit images using inpainting.
   *
   * Supports dall-e-2 and gpt-image-1. Upload an image and optionally a mask to
   * indicate which areas to regenerate based on the prompt.
   */
  edit(body: ImageEditParams, options?: RequestOptions): APIPromise<ImagesResponse> {
    return this._client.post(
      '/v1/images/edits',
      multipartFormRequestOptions({ body, ...options }, this._client),
    );
  }

  /**
   * Generate images from text prompts.
   *
   * Pure image generation models only (DALL-E, GPT Image). For multimodal models
   * like gemini-2.5-flash-image, use /v1/chat/completions.
   */
  generate(body: ImageGenerateParams, options?: RequestOptions): APIPromise<ImagesResponse> {
    return this._client.post('/v1/images/generations', { body, ...options });
  }
}

/**
 * Request to generate images.
 */
export interface CreateImageRequest {
  /**
   * A text description of the desired image(s). The maximum length is 32000
   * characters for `gpt-image-1`, 1000 characters for `dall-e-2` and 4000 characters
   * for `dall-e-3`.
   */
  prompt: string;

  /**
   * Allows to set transparency for the background of the generated image(s). This
   * parameter is only supported for `gpt-image-1`. Must be one of `transparent`,
   * `opaque` or `auto` (default value). When `auto` is used, the model will
   * automatically determine the best background for the image.
   *
   * If `transparent`, the output format needs to support transparency, so it should
   * be set to either `png` (default value) or `webp`.
   */
  background?: 'transparent' | 'opaque' | 'auto' | null;

  /**
   * The model to use for image generation. One of `openai/dall-e-2`,
   * `openai/dall-e-3`, or `openai/gpt-image-1`. Defaults to `openai/dall-e-2` unless
   * a parameter specific to `gpt-image-1` is used.
   */
  model?: string | null;

  /**
   * Control the content-moderation level for images generated by `gpt-image-1`. Must
   * be either `low` for less restrictive filtering or `auto` (default value).
   */
  moderation?: 'low' | 'auto' | null;

  /**
   * The number of images to generate. Must be between 1 and 10. For `dall-e-3`, only
   * `n=1` is supported.
   */
  n?: number | null;

  /**
   * The compression level (0-100%) for the generated images. This parameter is only
   * supported for `gpt-image-1` with the `webp` or `jpeg` output formats, and
   * defaults to 100.
   */
  output_compression?: number | null;

  /**
   * The format in which the generated images are returned. This parameter is only
   * supported for `gpt-image-1`. Must be one of `png`, `jpeg`, or `webp`.
   */
  output_format?: 'png' | 'jpeg' | 'webp' | null;

  /**
   * The number of partial images to generate. This parameter is used for streaming
   * responses that return partial images. Value must be between 0 and 3. When set to
   * 0, the response will be a single image sent in one streaming event.
   *
   * Note that the final image may be sent before the full number of partial images
   * are generated if the full image is generated more quickly.
   */
  partial_images?: number | null;

  /**
   * The quality of the image that will be generated.
   *
   * - `auto` (default value) will automatically select the best quality for the
   *   given model.
   * - `high`, `medium` and `low` are supported for `gpt-image-1`.
   * - `hd` and `standard` are supported for `dall-e-3`.
   * - `standard` is the only option for `dall-e-2`.
   */
  quality?: 'auto' | 'high' | 'medium' | 'low' | 'hd' | 'standard' | null;

  /**
   * The format in which generated images with `dall-e-2` and `dall-e-3` are
   * returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes
   * after the image has been generated. This parameter isn't supported for
   * `gpt-image-1` which will always return base64-encoded images.
   */
  response_format?: 'url' | 'b64_json' | null;

  /**
   * The size of the generated images. Must be one of `1024x1024`, `1536x1024`
   * (landscape), `1024x1536` (portrait), or `auto` (default value) for
   * `gpt-image-1`, one of `256x256`, `512x512`, or `1024x1024` for `dall-e-2`, and
   * one of `1024x1024`, `1792x1024`, or `1024x1792` for `dall-e-3`.
   */
  size?:
    | '256x256'
    | '512x512'
    | '1024x1024'
    | '1536x1024'
    | '1024x1536'
    | '1792x1024'
    | '1024x1792'
    | 'auto'
    | null;

  /**
   * Generate the image in streaming mode. Defaults to `false`. See the
   * [Image generation guide](https://platform.openai.com/docs/guides/image-generation)
   * for more information. This parameter is only supported for `gpt-image-1`.
   */
  stream?: boolean | null;

  /**
   * The style of the generated images. This parameter is only supported for
   * `dall-e-3`. Must be one of `vivid` or `natural`. Vivid causes the model to lean
   * towards generating hyper-real and dramatic images. Natural causes the model to
   * produce more natural, less hyper-real looking images.
   */
  style?: 'vivid' | 'natural' | null;

  /**
   * A unique identifier representing your end-user, which can help OpenAI to monitor
   * and detect abuse.
   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#end-user-ids).
   */
  user?: string | null;
}

/**
 * Single image object.
 */
export interface Image {
  /**
   * Base64-encoded image data (if response_format=b64_json)
   */
  b64_json?: string | null;

  /**
   * Revised prompt used for generation (dall-e-3)
   */
  revised_prompt?: string | null;

  /**
   * URL of the generated image (if response_format=url)
   */
  url?: string | null;
}

/**
 * Response from image generation.
 */
export interface ImagesResponse {
  /**
   * Unix timestamp when images were created
   */
  created: number;

  /**
   * List of generated images
   */
  data: Array<Image>;
}

export interface ImageCreateVariationParams {
  image: Uploadable;

  model?: string | null;

  n?: number | null;

  response_format?: string | null;

  size?: string | null;

  user?: string | null;
}

export interface ImageEditParams {
  image: Uploadable;

  prompt: string;

  mask?: Uploadable | null;

  model?: string | null;

  n?: number | null;

  response_format?: string | null;

  size?: string | null;

  user?: string | null;
}

export interface ImageGenerateParams {
  /**
   * A text description of the desired image(s). The maximum length is 32000
   * characters for `gpt-image-1`, 1000 characters for `dall-e-2` and 4000 characters
   * for `dall-e-3`.
   */
  prompt: string;

  /**
   * Allows to set transparency for the background of the generated image(s). This
   * parameter is only supported for `gpt-image-1`. Must be one of `transparent`,
   * `opaque` or `auto` (default value). When `auto` is used, the model will
   * automatically determine the best background for the image.
   *
   * If `transparent`, the output format needs to support transparency, so it should
   * be set to either `png` (default value) or `webp`.
   */
  background?: 'transparent' | 'opaque' | 'auto' | null;

  /**
   * The model to use for image generation. One of `openai/dall-e-2`,
   * `openai/dall-e-3`, or `openai/gpt-image-1`. Defaults to `openai/dall-e-2` unless
   * a parameter specific to `gpt-image-1` is used.
   */
  model?: string | null;

  /**
   * Control the content-moderation level for images generated by `gpt-image-1`. Must
   * be either `low` for less restrictive filtering or `auto` (default value).
   */
  moderation?: 'low' | 'auto' | null;

  /**
   * The number of images to generate. Must be between 1 and 10. For `dall-e-3`, only
   * `n=1` is supported.
   */
  n?: number | null;

  /**
   * The compression level (0-100%) for the generated images. This parameter is only
   * supported for `gpt-image-1` with the `webp` or `jpeg` output formats, and
   * defaults to 100.
   */
  output_compression?: number | null;

  /**
   * The format in which the generated images are returned. This parameter is only
   * supported for `gpt-image-1`. Must be one of `png`, `jpeg`, or `webp`.
   */
  output_format?: 'png' | 'jpeg' | 'webp' | null;

  /**
   * The number of partial images to generate. This parameter is used for streaming
   * responses that return partial images. Value must be between 0 and 3. When set to
   * 0, the response will be a single image sent in one streaming event.
   *
   * Note that the final image may be sent before the full number of partial images
   * are generated if the full image is generated more quickly.
   */
  partial_images?: number | null;

  /**
   * The quality of the image that will be generated.
   *
   * - `auto` (default value) will automatically select the best quality for the
   *   given model.
   * - `high`, `medium` and `low` are supported for `gpt-image-1`.
   * - `hd` and `standard` are supported for `dall-e-3`.
   * - `standard` is the only option for `dall-e-2`.
   */
  quality?: 'auto' | 'high' | 'medium' | 'low' | 'hd' | 'standard' | null;

  /**
   * The format in which generated images with `dall-e-2` and `dall-e-3` are
   * returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes
   * after the image has been generated. This parameter isn't supported for
   * `gpt-image-1` which will always return base64-encoded images.
   */
  response_format?: 'url' | 'b64_json' | null;

  /**
   * The size of the generated images. Must be one of `1024x1024`, `1536x1024`
   * (landscape), `1024x1536` (portrait), or `auto` (default value) for
   * `gpt-image-1`, one of `256x256`, `512x512`, or `1024x1024` for `dall-e-2`, and
   * one of `1024x1024`, `1792x1024`, or `1024x1792` for `dall-e-3`.
   */
  size?:
    | '256x256'
    | '512x512'
    | '1024x1024'
    | '1536x1024'
    | '1024x1536'
    | '1792x1024'
    | '1024x1792'
    | 'auto'
    | null;

  /**
   * Generate the image in streaming mode. Defaults to `false`. See the
   * [Image generation guide](https://platform.openai.com/docs/guides/image-generation)
   * for more information. This parameter is only supported for `gpt-image-1`.
   */
  stream?: boolean | null;

  /**
   * The style of the generated images. This parameter is only supported for
   * `dall-e-3`. Must be one of `vivid` or `natural`. Vivid causes the model to lean
   * towards generating hyper-real and dramatic images. Natural causes the model to
   * produce more natural, less hyper-real looking images.
   */
  style?: 'vivid' | 'natural' | null;

  /**
   * A unique identifier representing your end-user, which can help OpenAI to monitor
   * and detect abuse.
   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#end-user-ids).
   */
  user?: string | null;
}

export declare namespace Images {
  export {
    type CreateImageRequest as CreateImageRequest,
    type Image as Image,
    type ImagesResponse as ImagesResponse,
    type ImageCreateVariationParams as ImageCreateVariationParams,
    type ImageEditParams as ImageEditParams,
    type ImageGenerateParams as ImageGenerateParams,
  };
}
